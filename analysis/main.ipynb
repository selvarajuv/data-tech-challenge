{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "186d2d13",
   "metadata": {},
   "source": [
    "#### Data Cleaning and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e00f991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Suppress Prophet/cmdstanpy logging\n",
    "logging.getLogger('cmdstanpy').setLevel(logging.ERROR)\n",
    "logging.getLogger('prophet').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f05eff51",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load data into dataframe\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m airtraffic_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vichu\\miniconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vichu\\miniconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vichu\\miniconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vichu\\miniconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vichu\\miniconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data.csv'"
     ]
    }
   ],
   "source": [
    "# Load data into dataframe\n",
    "airtraffic_df = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2169dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at 10 rows\n",
    "airtraffic_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78c66af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display shape and type of df\n",
    "airtraffic_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7750e86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary statistics for the data\n",
    "airtraffic_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157578b4",
   "metadata": {},
   "source": [
    "HERE ARE THE VARIABLES THAT NEED TO CHANGE\n",
    "- Month -> String\n",
    "- AustralianPort -> String\n",
    "- ForeignPort -> String\n",
    "- Country -> String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e9d708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all of the nessesary varaibles\n",
    "changed_varaibles = [\"Month\", \"AustralianPort\", \"ForeignPort\", \"Country\"]\n",
    "\n",
    "for variable in changed_varaibles:\n",
    "    airtraffic_df[variable] = airtraffic_df[variable].astype(\"string\")\n",
    "\n",
    "# Check if changes worked\n",
    "airtraffic_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069ec51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the frequency of null values in each column\n",
    "airtraffic_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e1cfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the frequency of null values in each row\n",
    "airtraffic_df.isnull().sum(axis=1).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e177727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are duplicate rows\n",
    "duplicates = airtraffic_df.duplicated()\n",
    "print(f\"Number of duplicate rows: {duplicates.sum()}\")\n",
    "\n",
    "# Display duplicate rows\n",
    "if duplicates.sum() > 0:\n",
    "    duplicate_rows = airtraffic_df[duplicates]\n",
    "    display(duplicate_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dac72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check numberical columns are positive\n",
    "numerical_cols = ['Passengers_In', 'Passengers_Out', 'Passengers_Total', \n",
    "                  'Freight_In_(tonnes)', 'Freight_Out_(tonnes)', 'Freight_Total_(tonnes)',\n",
    "                  'Mail_In_(tonnes)', 'Mail_Out_(tonnes)', 'Mail_Total_(tonnes)']\n",
    "\n",
    "for col in numerical_cols:\n",
    "    invalid_mask = airtraffic_df[col] < 0\n",
    "    invalid_count = invalid_mask.sum()\n",
    "\n",
    "print(f\"Number of invalid rows: {invalid_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55abb11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check month_num is within 1-12\n",
    "invalid_months = len(airtraffic_df[(airtraffic_df['Month_num'] < 1) | (airtraffic_df['Month_num'] > 12)])\n",
    "\n",
    "print(f\"Number of rows with an invalid month_num: {invalid_months}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21fab75",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8183c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the custom analyzer\n",
    "from traffic_analyzer import TrafficAnalyzer\n",
    "\n",
    "# Initialize the analyzer with your cleaned data\n",
    "analyzer = TrafficAnalyzer(airtraffic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d54549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPASSENGER TRAFFIC ANALYSIS - ALL DIRECTIONS\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "# Create comparison table for passengers\n",
    "passenger_total = analyzer.analyze_ranking('passengers', 'total', 'route', 5, 5)\n",
    "passenger_in = analyzer.analyze_ranking('passengers', 'in', 'route', 5, 5)\n",
    "passenger_out = analyzer.analyze_ranking('passengers', 'out', 'route', 5, 5)\n",
    "\n",
    "print(\"\\nTop 5 Passenger Routes - Comparison:\")\n",
    "passenger_comparison = passenger_total['data']['top'][['AustralianPort', 'ForeignPort']].copy()\n",
    "passenger_comparison['Total'] = passenger_total['data']['top']['Passengers_Total']\n",
    "display(passenger_comparison)\n",
    "\n",
    "# Add in and out data\n",
    "for idx, row in passenger_comparison.iterrows():\n",
    "    route_data = airtraffic_df[\n",
    "        (airtraffic_df['AustralianPort'] == row['AustralianPort']) & \n",
    "        (airtraffic_df['ForeignPort'] == row['ForeignPort'])\n",
    "    ]\n",
    "    passenger_comparison.loc[idx, 'Inbound'] = route_data['Passengers_In'].sum()\n",
    "    passenger_comparison.loc[idx, 'Outbound'] = route_data['Passengers_Out'].sum()\n",
    "\n",
    "passenger_comparison['Route'] = passenger_comparison['AustralianPort'] + ' ↔ ' + passenger_comparison['ForeignPort']\n",
    "display(passenger_comparison[['Route', 'Inbound', 'Outbound', 'Total']])\n",
    "\n",
    "print(\"\\nBottom 5 Passenger Routes - Comparison:\")\n",
    "passenger_bottom_comparison = passenger_total['data']['bottom'][['AustralianPort', 'ForeignPort']].copy()\n",
    "passenger_bottom_comparison['Total'] = passenger_total['data']['bottom']['Passengers_Total']\n",
    "\n",
    "# Add in and out data for bottom routes\n",
    "for idx, row in passenger_bottom_comparison.iterrows():\n",
    "    route_data = airtraffic_df[\n",
    "        (airtraffic_df['AustralianPort'] == row['AustralianPort']) & \n",
    "        (airtraffic_df['ForeignPort'] == row['ForeignPort'])\n",
    "    ]\n",
    "    passenger_bottom_comparison.loc[idx, 'Inbound'] = route_data['Passengers_In'].sum()\n",
    "    passenger_bottom_comparison.loc[idx, 'Outbound'] = route_data['Passengers_Out'].sum()\n",
    "\n",
    "passenger_bottom_comparison['Route'] = passenger_bottom_comparison['AustralianPort'] + ' ↔ ' + passenger_bottom_comparison['ForeignPort']\n",
    "display(passenger_bottom_comparison[['Route', 'Inbound', 'Outbound', 'Total']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edfb156",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nFREIGHT TRAFFIC ANALYSIS - ALL DIRECTIONS\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "# Create comparison table for freight\n",
    "freight_total = analyzer.analyze_ranking('freight', 'total', 'route', 5, 5)\n",
    "freight_in = analyzer.analyze_ranking('freight', 'in', 'route', 5, 5)\n",
    "freight_out = analyzer.analyze_ranking('freight', 'out', 'route', 5, 5)\n",
    "\n",
    "print(\"\\nTop 5 Freight Routes - Comparison:\")\n",
    "freight_comparison = freight_total['data']['top'][['AustralianPort', 'ForeignPort']].copy()\n",
    "freight_comparison['Total'] = freight_total['data']['top']['Freight_Total_(tonnes)']\n",
    "\n",
    "# Add in and out data\n",
    "for idx, row in freight_comparison.iterrows():\n",
    "    route_data = airtraffic_df[\n",
    "        (airtraffic_df['AustralianPort'] == row['AustralianPort']) & \n",
    "        (airtraffic_df['ForeignPort'] == row['ForeignPort'])\n",
    "    ]\n",
    "    freight_comparison.loc[idx, 'Inbound'] = route_data['Freight_In_(tonnes)'].sum()\n",
    "    freight_comparison.loc[idx, 'Outbound'] = route_data['Freight_Out_(tonnes)'].sum()\n",
    "\n",
    "freight_comparison['Route'] = freight_comparison['AustralianPort'] + ' ↔ ' + freight_comparison['ForeignPort']\n",
    "display(freight_comparison[['Route', 'Inbound', 'Outbound', 'Total']])\n",
    "\n",
    "print(\"\\nBottom 5 Freight Routes - Comparison:\")\n",
    "freight_bottom_comparison = freight_total['data']['bottom'][['AustralianPort', 'ForeignPort']].copy()\n",
    "freight_bottom_comparison['Total'] = freight_total['data']['bottom']['Freight_Total_(tonnes)']\n",
    "\n",
    "# Add in and out data for bottom routes\n",
    "for idx, row in freight_bottom_comparison.iterrows():\n",
    "    route_data = airtraffic_df[\n",
    "        (airtraffic_df['AustralianPort'] == row['AustralianPort']) & \n",
    "        (airtraffic_df['ForeignPort'] == row['ForeignPort'])\n",
    "    ]\n",
    "    freight_bottom_comparison.loc[idx, 'Inbound'] = route_data['Freight_In_(tonnes)'].sum()\n",
    "    freight_bottom_comparison.loc[idx, 'Outbound'] = route_data['Freight_Out_(tonnes)'].sum()\n",
    "\n",
    "freight_bottom_comparison['Route'] = freight_bottom_comparison['AustralianPort'] + ' ↔ ' + freight_bottom_comparison['ForeignPort']\n",
    "display(freight_bottom_comparison[['Route', 'Inbound', 'Outbound', 'Total']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3db43b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMAIL TRAFFIC ANALYSIS - ALL DIRECTIONS\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "# Create comparison table for mail\n",
    "mail_total = analyzer.analyze_ranking('mail', 'total', 'route', 5, 5)\n",
    "mail_in = analyzer.analyze_ranking('mail', 'in', 'route', 5, 5)\n",
    "mail_out = analyzer.analyze_ranking('mail', 'out', 'route', 5, 5)\n",
    "\n",
    "print(\"\\nTop 5 Mail Routes - Comparison:\")\n",
    "mail_comparison = mail_total['data']['top'][['AustralianPort', 'ForeignPort']].copy()\n",
    "mail_comparison['Total'] = mail_total['data']['top']['Mail_Total_(tonnes)']\n",
    "\n",
    "# Add in and out data\n",
    "for idx, row in mail_comparison.iterrows():\n",
    "    route_data = airtraffic_df[\n",
    "        (airtraffic_df['AustralianPort'] == row['AustralianPort']) & \n",
    "        (airtraffic_df['ForeignPort'] == row['ForeignPort'])\n",
    "    ]\n",
    "    mail_comparison.loc[idx, 'Inbound'] = route_data['Mail_In_(tonnes)'].sum()\n",
    "    mail_comparison.loc[idx, 'Outbound'] = route_data['Mail_Out_(tonnes)'].sum()\n",
    "\n",
    "mail_comparison['Route'] = mail_comparison['AustralianPort'] + ' ↔ ' + mail_comparison['ForeignPort']\n",
    "display(mail_comparison[['Route', 'Inbound', 'Outbound', 'Total']])\n",
    "\n",
    "print(\"\\nBottom 5 Mail Routes - Comparison:\")\n",
    "mail_bottom_comparison = mail_total['data']['bottom'][['AustralianPort', 'ForeignPort']].copy()\n",
    "mail_bottom_comparison['Total'] = mail_total['data']['bottom']['Mail_Total_(tonnes)']\n",
    "\n",
    "# Add in and out data for bottom routes\n",
    "for idx, row in mail_bottom_comparison.iterrows():\n",
    "    route_data = airtraffic_df[\n",
    "        (airtraffic_df['AustralianPort'] == row['AustralianPort']) & \n",
    "        (airtraffic_df['ForeignPort'] == row['ForeignPort'])\n",
    "    ]\n",
    "    mail_bottom_comparison.loc[idx, 'Inbound'] = route_data['Mail_In_(tonnes)'].sum()\n",
    "    mail_bottom_comparison.loc[idx, 'Outbound'] = route_data['Mail_Out_(tonnes)'].sum()\n",
    "\n",
    "mail_bottom_comparison['Route'] = mail_bottom_comparison['AustralianPort'] + ' ↔ ' + mail_bottom_comparison['ForeignPort']\n",
    "display(mail_bottom_comparison[['Route', 'Inbound', 'Outbound', 'Total']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400a3341",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPASSENGER TEMPORAL TRENDS ANALYSIS\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "# Overall traffic trends over time\n",
    "temporal_result = analyzer.analyze_temporal('passengers', 'total', groupby_level='total')\n",
    "\n",
    "print(\"\\nMonthly Passenger Traffic Trends:\")\n",
    "display(temporal_result['data'][['Month_dt', 'Passengers_Total', 'MoM_Growth', '3M_MA']].tail(12))\n",
    "\n",
    "print(\"\\nKey Metrics:\")\n",
    "print(f\"  Monthly Growth Rate: {temporal_result['statistics']['trend_pct_monthly']:.2f}%\")\n",
    "print(f\"  Total Period Growth: {((temporal_result['statistics']['end_value'] - temporal_result['statistics']['start_value']) / temporal_result['statistics']['start_value'] * 100):.1f}%\")\n",
    "print(f\"  Volatility (CV): {temporal_result['statistics']['cv']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59755f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nFREIGHT TEMPORAL TRENDS ANALYSIS\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "# Overall traffic trends over time\n",
    "temporal_result = analyzer.analyze_temporal('freight', 'total', groupby_level='total')\n",
    "\n",
    "print(\"\\nMonthly Freight Traffic Trends:\")\n",
    "display(temporal_result['data'][['Month_dt', 'Freight_Total_(tonnes)', 'MoM_Growth', '3M_MA']].tail(12))\n",
    "\n",
    "print(\"\\nKey Metrics:\")\n",
    "print(f\"  Monthly Growth Rate: {temporal_result['statistics']['trend_pct_monthly']:.2f}%\")\n",
    "print(f\"  Total Period Growth: {((temporal_result['statistics']['end_value'] - temporal_result['statistics']['start_value']) / temporal_result['statistics']['start_value'] * 100):.1f}%\")\n",
    "print(f\"  Volatility (CV): {temporal_result['statistics']['cv']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f1d06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMAIL TEMPORAL TRENDS ANALYSIS\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "# Overall traffic trends over time\n",
    "temporal_result = analyzer.analyze_temporal('mail', 'total', groupby_level='total')\n",
    "\n",
    "print(\"\\nMonthly Freight Traffic Trends:\")\n",
    "display(temporal_result['data'][['Month_dt', 'Mail_Total_(tonnes)', 'MoM_Growth', '3M_MA']].tail(12))\n",
    "\n",
    "print(\"\\nKey Metrics:\")\n",
    "print(f\"  Monthly Growth Rate: {temporal_result['statistics']['trend_pct_monthly']:.2f}%\")\n",
    "print(f\"  Total Period Growth: {((temporal_result['statistics']['end_value'] - temporal_result['statistics']['start_value']) / temporal_result['statistics']['start_value'] * 100):.1f}%\")\n",
    "print(f\"  Volatility (CV): {temporal_result['statistics']['cv']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c88bf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPASSENGER SEASONAL PATTERNS ANALYSIS\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "seasonal_result = analyzer.analyze_seasonal('passengers', 'total', 'total')\n",
    "\n",
    "month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "seasonal_df = seasonal_result['data'].copy()\n",
    "seasonal_df['Month'] = [month_names[i-1] for i in seasonal_df['Month_Num']]\n",
    "\n",
    "print(\"\\nAverage Traffic by Month:\")\n",
    "display(seasonal_df[['Month', 'Passengers_Total']])\n",
    "\n",
    "print(\"Seasonality Metrics:\")\n",
    "print(f\"  Peak Month: {month_names[seasonal_result['statistics']['peak_month']-1]}\")\n",
    "print(f\"  Trough Month: {month_names[seasonal_result['statistics']['trough_month']-1]}\")\n",
    "print(f\"  Seasonal Strength: {seasonal_result['statistics']['seasonal_strength']:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552ad225",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nFREIGHT SEASONAL PATTERNS ANALYSIS\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "seasonal_result = analyzer.analyze_seasonal('freight', 'total', 'total')\n",
    "\n",
    "month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "seasonal_df = seasonal_result['data'].copy()\n",
    "seasonal_df['Month'] = [month_names[i-1] for i in seasonal_df['Month_Num']]\n",
    "\n",
    "print(\"\\nAverage Traffic by Month:\")\n",
    "display(seasonal_df[['Month', 'Freight_Total_(tonnes)']])\n",
    "\n",
    "print(\"Seasonality Metrics:\")\n",
    "print(f\"  Peak Month: {month_names[seasonal_result['statistics']['peak_month']-1]}\")\n",
    "print(f\"  Trough Month: {month_names[seasonal_result['statistics']['trough_month']-1]}\")\n",
    "print(f\"  Seasonal Strength: {seasonal_result['statistics']['seasonal_strength']:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02716877",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMAIL SEASONAL PATTERNS ANALYSIS\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "seasonal_result = analyzer.analyze_seasonal('mail', 'total', 'total')\n",
    "\n",
    "month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "seasonal_df = seasonal_result['data'].copy()\n",
    "seasonal_df['Month'] = [month_names[i-1] for i in seasonal_df['Month_Num']]\n",
    "\n",
    "print(\"\\nAverage Traffic by Month:\")\n",
    "display(seasonal_df[['Month', 'Mail_Total_(tonnes)']])\n",
    "\n",
    "print(\"Seasonality Metrics:\")\n",
    "print(f\"  Peak Month: {month_names[seasonal_result['statistics']['peak_month']-1]}\")\n",
    "print(f\"  Trough Month: {month_names[seasonal_result['statistics']['trough_month']-1]}\")\n",
    "print(f\"  Seasonal Strength: {seasonal_result['statistics']['seasonal_strength']:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab65ffce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPASSENGER GEOGRAPHICAL PATTERNS ANALYSIS\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "# By Country\n",
    "country_result = analyzer.analyze_ranking('passengers', 'total', 'country', 5, 5)\n",
    "\n",
    "print(\"\\nTop 10 Countries by Passenger Traffic:\")\n",
    "country_df = country_result['data']['top'].copy()\n",
    "country_df['% of Total'] = (country_df['Passengers_Total'] / country_df['Passengers_Total'].sum() * 100)\n",
    "display(country_df[['Label', 'Passengers_Total', '% of Total']])\n",
    "\n",
    "# By Australian Port\n",
    "port_result = analyzer.analyze_ranking('passengers', 'total', 'port', 5, 5)\n",
    "\n",
    "print(\"\\nAustralian Port Hub Analysis:\")\n",
    "display(port_result['data']['top'][['Label', 'Passengers_Total']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7104fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nFREIGHT GEOGRAPHICAL PATTERNS ANALYSIS\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "# By Country\n",
    "country_result = analyzer.analyze_ranking('freight', 'total', 'country', 5, 5)\n",
    "\n",
    "print(\"\\nTop 10 Countries by Freight Traffic:\")\n",
    "country_df = country_result['data']['top'].copy()\n",
    "country_df['% of Total'] = (country_df['Freight_Total_(tonnes)'] / country_df['Freight_Total_(tonnes)'].sum() * 100)\n",
    "display(country_df[['Label', 'Freight_Total_(tonnes)', '% of Total']])\n",
    "\n",
    "# By Australian Port (Hub Analysis)\n",
    "port_result = analyzer.analyze_ranking('freight', 'total', 'port', 5, 5)\n",
    "\n",
    "print(\"\\nAustralian Port Hub Analysis:\")\n",
    "display(port_result['data']['top'][['Label', 'Freight_Total_(tonnes)']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ae566f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMAIL GEOGRAPHICAL PATTERNS ANALYSIS\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "# By Country\n",
    "country_result = analyzer.analyze_ranking('mail', 'total', 'country', 5, 5)\n",
    "\n",
    "print(\"\\nTop 10 Countries by Mail Traffic:\")\n",
    "country_df = country_result['data']['top'].copy()\n",
    "country_df['% of Total'] = (country_df['Mail_Total_(tonnes)'] / country_df['Mail_Total_(tonnes)'].sum() * 100)\n",
    "display(country_df[['Label', 'Mail_Total_(tonnes)', '% of Total']])\n",
    "\n",
    "# By Australian Port (Hub Analysis)\n",
    "port_result = analyzer.analyze_ranking('mail', 'total', 'port', 5, 5)\n",
    "\n",
    "print(\"\\nAustralian Port Hub Analysis:\")\n",
    "display(port_result['data']['top'][['Label', 'Mail_Total_(tonnes)']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96302b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPASSENGER TRAFFIC BALANCE ANALYSIS\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "balance_result = analyzer.analyze_balance('passengers', groupby_level='route')\n",
    "\n",
    "print(\"\\nMost Imbalanced Routes:\")\n",
    "balance_df = balance_result['data'].head(10).copy()\n",
    "balance_df['Status'] = balance_df['Balance_Ratio'].apply(\n",
    "    lambda x: 'Balanced' if 0.8 <= x <= 1.2 else 'Imbalanced' if pd.notna(x) else 'N/A'\n",
    ")\n",
    "display(balance_df[['Label', 'Passengers_In', 'Passengers_Out', 'Balance_Ratio', 'Status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b84eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nFREIGHT TRAFFIC BALANCE ANALYSIS\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "balance_result = analyzer.analyze_balance('freight', groupby_level='route')\n",
    "\n",
    "print(\"\\nMost Imbalanced Routes:\")\n",
    "balance_df = balance_result['data'].head(10).copy()\n",
    "balance_df['Status'] = balance_df['Balance_Ratio'].apply(\n",
    "    lambda x: 'Balanced' if 0.8 <= x <= 1.2 else 'Imbalanced' if pd.notna(x) else 'N/A'\n",
    ")\n",
    "display(balance_df[['Label', 'Freight_In_(tonnes)', 'Freight_Out_(tonnes)', 'Balance_Ratio', 'Status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08b0f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMAIL TRAFFIC BALANCE ANALYSIS\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "balance_result = analyzer.analyze_balance('mail', groupby_level='route')\n",
    "\n",
    "print(\"\\nMost Imbalanced Routes:\")\n",
    "balance_df = balance_result['data'].head(10).copy()\n",
    "balance_df['Status'] = balance_df['Balance_Ratio'].apply(\n",
    "    lambda x: 'Balanced' if 0.8 <= x <= 1.2 else 'Imbalanced' if pd.notna(x) else 'N/A'\n",
    ")\n",
    "display(balance_df[['Label', 'Mail_In_(tonnes)', 'Mail_Out_(tonnes)', 'Balance_Ratio', 'Status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fe12d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nGROWTH OPPORTUNITIES AND RISK ANALYSIS\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "# High growth routes\n",
    "opportunities = analyzer.find_opportunities(min_growth_rate=3.0)\n",
    "if len(opportunities) > 0:\n",
    "    print(\"\\nHigh Growth Routes (>3% monthly growth):\")\n",
    "    display(opportunities[['route', 'monthly_growth', 'period_growth', 'current_volume', 'potential']].head(10))\n",
    "\n",
    "# Declining routes\n",
    "risks = analyzer.identify_risks(max_decline_rate=-2.0)\n",
    "if len(risks) > 0:\n",
    "    print(\"\\nDeclining Routes (<2% monthly decline):\")\n",
    "    display(risks[['route', 'monthly_decline', 'period_decline', 'current_volume', 'risk_level']].head(10))\n",
    "\n",
    "print(\"ROUTES SELECTED FOR FORECASTING:\\n\")\n",
    "\n",
    "# Top performers\n",
    "print(\"1. HIGH-VOLUME ROUTES (Critical for business):\")\n",
    "top_routes = passenger_total['data']['top'].head(3)\n",
    "for idx, row in top_routes.iterrows():\n",
    "    print(f\"   • {row['AustralianPort']} ↔ {row['ForeignPort']} - {row['Passengers_Total']:,.0f} total passengers\")\n",
    "\n",
    "# High growth opportunities \n",
    "if len(opportunities) > 0:\n",
    "    print(\"\\n2. HIGH-GROWTH OPPORTUNITIES (Potential investment targets):\")\n",
    "    for idx, row in opportunities.head(2).iterrows():\n",
    "        print(f\"   • {row['route']} - {row['monthly_growth']:.1f}% monthly growth\")\n",
    "\n",
    "# Declining routes\n",
    "if len(risks) > 0:\n",
    "    print(\"\\n3. DECLINING ROUTES (Risk management needed):\")\n",
    "    for idx, row in risks.head(2).iterrows():\n",
    "        print(f\"   • {row['route']} - {row['monthly_decline']:.1f}% monthly decline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b718f413",
   "metadata": {},
   "source": [
    "### MODEL SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9ec502",
   "metadata": {},
   "outputs": [],
   "source": [
    "from route_forcaster import RouteForecaster\n",
    "from future_forcaster import FutureForecaster\n",
    "\n",
    "routes = ['Sydney-Auckland', 'Sydney-Singapore', 'Sydney-Tokyo']\n",
    "summary_data = []\n",
    "\n",
    "for route in routes:\n",
    "    # Run analysis\n",
    "    rf = RouteForecaster(airtraffic_df, route, 'passengers', 'total')\n",
    "    rf.run_complete_analysis()\n",
    "    \n",
    "    # Generate future forecasts\n",
    "    ff = FutureForecaster(rf)\n",
    "    ff.get_best_model_forecast(n_months=12)\n",
    "    \n",
    "    # Plot visualization\n",
    "    ff.plot_future_forecast(model_name=rf.metrics and min(rf.metrics.keys(), key=lambda x: rf.metrics[x]['MAPE']))\n",
    "    \n",
    "    # Summary report\n",
    "    ff.summary_report()\n",
    "    \n",
    "    # Collect for table\n",
    "    best_model = min(rf.metrics.keys(), key=lambda x: rf.metrics[x]['MAPE'])\n",
    "    forecast = ff.future_predictions[best_model]['forecast']\n",
    "    \n",
    "    summary_data.append({\n",
    "        'Route': route,\n",
    "        'Best Model': best_model,\n",
    "        'MAPE (%)': rf.metrics[best_model]['MAPE'],\n",
    "        '6-Month Avg': forecast[:6].mean(),\n",
    "        '12-Month Avg': forecast.mean(),\n",
    "        'Growth (%)': ((forecast[-1] - forecast[0]) / forecast[0] * 100)\n",
    "    })\n",
    "\n",
    "# Display summary table\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(\"\\nSUMMARY TABLE\")\n",
    "display(summary_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
